{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from utils import *\n",
    "from agoda_cancellation_estimator import *\n",
    "import agoda_cancellation_preprocessor\n",
    "from agoda_cancellation_prediction import *\n",
    "from agoda_cancellation_preprocessor import AgodaCancellationPreprocessor\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, recall_score, \\\n",
    "    precision_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, \\\n",
    "    GradientBoostingClassifier\n",
    "\n",
    "import importlib\n",
    "\n",
    "importlib.reload(agoda_cancellation_preprocessor)\n",
    "from agoda_cancellation_preprocessor import *\n",
    "\n",
    "np.random.seed(0)\n",
    "c = [custom[0], custom[-1]]\n",
    "\n",
    "# Load and preprocess data\n",
    "full_data = load_data(\n",
    "    \"../datasets/agoda_cancellation_train.csv\")\n",
    "p = AgodaCancellationPreprocessor(full_data)\n",
    "base_design_matrix, week_specific = p.preprocess(full_data)\n",
    "cancellation_labels_list = p.preprocess_labels(full_data.cancellation_datetime,\n",
    "                                          full_data.booking_datetime)\n",
    "design_matrix = pd.DataFrame()\n",
    "cancellation_labels = pd.DataFrame()\n",
    "for i in range(len(week_specific)):\n",
    "\tpd.concat([design_matrix, pd.concat([base_design_matrix,week_specific[i]], axis=1)])\n",
    "\tpd.concat([cancellation_labels, cancellation_labels_list[i]])\n",
    "for i in range(1, WEEK - 3):\n",
    "\tweek_data = pd.read_csv(f\"test_set_week_{i}.csv\")\n",
    "\ttest_set_i = p.preprocess(week_data)[0]\n",
    "\ttest_set_i_labels = pd.read_csv(f\"test_set_week_{i}_labels.csv\")[\n",
    "        \"h_booking_id|label\"].astype(str).apply(lambda x: int(x[-1]))\n",
    "\tp.add_week_features(test_set_i, week_data)\n",
    "\tdesign_matrix = pd.concat(\n",
    "        [design_matrix, test_set_i])\n",
    "\tcancellation_labels = pd.concat(\n",
    "        [cancellation_labels, test_set_i_labels])\n",
    "\ttest_set_i = fill_missing_columns(design_matrix, test_set_i)\n",
    "\n",
    "week_data = pd.read_csv(f\"test_set_week_{WEEK-2}.csv\")\n",
    "train_test_set = p.preprocess(week_data)[0]\n",
    "train_test_set_labels = pd.read_csv(f\"test_set_week_{WEEK-2}_labels.csv\")[\n",
    "\t\"h_booking_id|label\"].astype(str).apply(lambda x: int(x[-1]))\n",
    "p.add_week_features(train_test_set, week_data)\n",
    "train_test_set = fill_missing_columns(design_matrix, train_test_set)\n",
    "\n",
    "\n",
    "week_data = pd.read_csv(f\"test_set_week_{WEEK-1}.csv\")\n",
    "test_set = p.preprocess(week_data)[0]\n",
    "test_set_labels = pd.read_csv(f\"test_set_week_{WEEK-2}_labels.csv\")[\n",
    "\t\"h_booking_id|label\"].astype(str).apply(lambda x: int(x[-1]))\n",
    "p.add_week_features(test_set, week_data)\n",
    "test_set = fill_missing_columns(design_matrix, test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.5231143552311436, precision score: 0.6070402298850575, recall score: 0.5170052499429354.\n",
      "[[671   3]\n",
      " [ 25   1]]\n",
      "f1 score: 0.48867786705624544, precision score: 0.481294964028777, recall score: 0.49629080118694363.\n",
      "[[669   5]\n",
      " [ 26   0]]\n",
      "\n",
      "f1 score: 0.5231143552311436, precision score: 0.6070402298850575, recall score: 0.5170052499429354.\n",
      "[[671   3]\n",
      " [ 25   1]]\n",
      "f1 score: 0.48867786705624544, precision score: 0.481294964028777, recall score: 0.49629080118694363.\n",
      "[[669   5]\n",
      " [ 26   0]]\n",
      "\n",
      "f1 score: 0.5231143552311436, precision score: 0.6070402298850575, recall score: 0.5170052499429354.\n",
      "[[671   3]\n",
      " [ 25   1]]\n",
      "f1 score: 0.48867786705624544, precision score: 0.481294964028777, recall score: 0.49629080118694363.\n",
      "[[669   5]\n",
      " [ 26   0]]\n",
      "\n",
      "f1 score: 0.5231143552311436, precision score: 0.6070402298850575, recall score: 0.5170052499429354.\n",
      "[[671   3]\n",
      " [ 25   1]]\n",
      "f1 score: 0.48867786705624544, precision score: 0.481294964028777, recall score: 0.49629080118694363.\n",
      "[[669   5]\n",
      " [ 26   0]]\n",
      "\n",
      "f1 score: 0.5231143552311436, precision score: 0.6070402298850575, recall score: 0.5170052499429354.\n",
      "[[671   3]\n",
      " [ 25   1]]\n",
      "f1 score: 0.48867786705624544, precision score: 0.481294964028777, recall score: 0.49629080118694363.\n",
      "[[669   5]\n",
      " [ 26   0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import agoda_cancellation_estimator\n",
    "import importlib\n",
    "\n",
    "importlib.reload(agoda_cancellation_estimator)\n",
    "from agoda_cancellation_estimator import *\n",
    "\n",
    "train_X = design_matrix\n",
    "train_y = np.array(cancellation_labels).reshape((-1,))\n",
    "test_X = test_set\n",
    "test_y = np.array(test_set_labels).reshape((-1,))\n",
    "train_test_X = train_test_set\n",
    "train_test_y = train_test_set_labels\n",
    "\n",
    "# Fit model over data with different model seeds.\n",
    "scores = []\n",
    "for n in range(5):\n",
    "\tnp.random.seed(0)\n",
    "\t# model = AgodaEnsembleCancellationEstimator(train_test_set, train_test_set_labels, verbose=True).fit(\n",
    "\t# \ttrain_X, train_y)\n",
    "\tmodel=GradientBoostingClassifier().fit(train_X,train_y)\n",
    "\ty_pred = model.predict(test_X)\n",
    "\tf1 = f1_score(test_y, y_pred, labels=[0, 1], average=\"macro\")\n",
    "\tprecision = precision_score(test_y, y_pred, labels=[0, 1],\n",
    "\t\t\t\t\t\t\t\taverage=\"macro\")\n",
    "\trecall = recall_score(test_y, y_pred, labels=[0, 1], average=\"macro\")\n",
    "\tprint(\n",
    "\t\tf\"f1 score: {f1}, precision score: {precision}, recall score: {recall}.\")\n",
    "\tprint(confusion_matrix(test_y, y_pred, labels=[0, 1]))\n",
    "\ty_pred = model.predict(train_test_X)\n",
    "\tf1 = f1_score(train_test_y, y_pred, labels=[0, 1], average=\"macro\")\n",
    "\tprecision = precision_score(train_test_y, y_pred, labels=[0, 1],\n",
    "\t\t\t\t\t\t\t\taverage=\"macro\")\n",
    "\trecall = recall_score(train_test_y, y_pred, labels=[0, 1], average=\"macro\")\n",
    "\tprint(\n",
    "\t\tf\"f1 score: {f1}, precision score: {precision}, recall score: {recall}.\")\n",
    "\tprint(confusion_matrix(train_test_y, y_pred, labels=[0, 1]))\n",
    "\tprint()\n",
    "# scores.append(f1)\n",
    "\n",
    "# for score in scores:\n",
    "#     print(score)\n",
    "# print(\"max score:\", max(scores))\n",
    "\n",
    "# for threshold in range(5,10):\n",
    "#     y_result = (y_prob > threshold).astype(int)\n",
    "#     scores.append((f1, precision, recall))\n",
    "# print()\n",
    "#\n",
    "# plot_data = [[], [], [], [], []]\n",
    "# for i, num_of_trees in enumerate(tree_range):\n",
    "#     for j, max_depth in enumerate(depth_range):\n",
    "#         plot_data[0].append(num_of_trees)\n",
    "#         plot_data[1].append(max_depth)\n",
    "#         plot_data[2].append(scores[i][j][0])\n",
    "#         plot_data[3].append(scores[i][j][1])\n",
    "#         plot_data[4].append(scores[i][j][2])\n",
    "#\n",
    "# print(\"plotting...\")\n",
    "# go.Figure(data=[go.Scatter3d(x=plot_data[0], z=plot_data[1], y=plot_data[2],\n",
    "#                              mode='markers',\n",
    "#                              marker=dict(color=plot_data[2], reversescale=True,\n",
    "#                                          showscale=True, size=3))],\n",
    "#           layout=go.Layout(\n",
    "#               title=r\"$\\text{f1 scores}$\",\n",
    "#               scene_aspectmode=\"cube\", showlegend=False,\n",
    "#               scene=dict(xaxis_title=\"num_of_trees\",\n",
    "#                          yaxis_title=\"max_depth\",\n",
    "#                          zaxis_title=\"f1_score\",\n",
    "#                          camera=dict(eye=dict(x=1, y=-1.8,\n",
    "#                                               z=.1))))).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}