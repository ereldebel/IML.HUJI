{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from challenge import agoda_cancellation_prediction\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from utils import *\n",
    "from agoda_cancellation_estimator import *\n",
    "import agoda_cancellation_preprocessor\n",
    "from agoda_cancellation_prediction import *\n",
    "from agoda_cancellation_preprocessor import AgodaCancellationPreprocessor\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, recall_score,\\\n",
    "\tprecision_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier,\\\n",
    "\tGradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import RidgeClassifierCV, RidgeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import importlib\n",
    "\n",
    "importlib.reload(agoda_cancellation_preprocessor)\n",
    "from agoda_cancellation_preprocessor import *\n",
    "\n",
    "importlib.reload(agoda_cancellation_prediction)\n",
    "from agoda_cancellation_prediction import *\n",
    "\n",
    "np.random.seed(0)\n",
    "c = [custom[0], custom[-1]]\n",
    "\n",
    "# Load and preprocess data\n",
    "full_data = load_data(\n",
    "\t\"../datasets/agoda_cancellation_train.csv\")\n",
    "p = AgodaCancellationPreprocessor(full_data)\n",
    "base_design_matrix, week_specific = p.preprocess(full_data)\n",
    "cancellation_labels_list = p.preprocess_labels(full_data.cancellation_datetime,\n",
    "                                               full_data.booking_datetime)\n",
    "design_matrix = pd.DataFrame()\n",
    "cancellation_labels = pd.DataFrame()\n",
    "for i in range(len(week_specific)):\n",
    "\tpd.concat([design_matrix,\n",
    "\t           pd.concat([base_design_matrix, week_specific[i]], axis=1)])\n",
    "\tpd.concat([cancellation_labels, cancellation_labels_list[i]])\n",
    "for i in range(1, WEEK - 3):\n",
    "\tweek_data = pd.read_csv(f\"week_{i}_test_data.csv\")\n",
    "\ttest_set_i = p.preprocess(week_data)[0]\n",
    "\ttest_set_i_labels = pd.read_csv(f\"week_{i}_labels.csv\")[\n",
    "\t\t\"cancel\"].astype(int)\n",
    "\tp.add_week_features(test_set_i, week_data)\n",
    "\tdesign_matrix = pd.concat(\n",
    "\t\t[design_matrix, test_set_i])\n",
    "\tcancellation_labels = pd.concat(\n",
    "\t\t[cancellation_labels, test_set_i_labels])\n",
    "\ttest_set_i = fill_missing_columns(design_matrix, test_set_i)\n",
    "\n",
    "week_data = pd.read_csv(f\"week_{WEEK - 2}_test_data.csv\")\n",
    "train_test_set = p.preprocess(week_data)[0]\n",
    "train_test_set_labels = pd.read_csv(f\"week_{WEEK - 2}_labels.csv\")[\n",
    "\t\"cancel\"].astype(int)\n",
    "p.add_week_features(train_test_set, week_data)\n",
    "train_test_set = fill_missing_columns(design_matrix, train_test_set)\n",
    "\n",
    "week_data = pd.read_csv(f\"week_{WEEK - 1}_test_data.csv\")\n",
    "test_set = p.preprocess(week_data)[0]\n",
    "test_set_labels = pd.read_csv(f\"week_{WEEK - 2}_labels.csv\")[\n",
    "\t\"cancel\"].astype(int)\n",
    "p.add_week_features(test_set, week_data)\n",
    "test_set = fill_missing_columns(design_matrix, test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\0erel\\onedrive\\documents\\cs.bsc\\semd\\iml\\iml.huji repo\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "1600 fits failed out of a total of 1600.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1600 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\0erel\\onedrive\\documents\\cs.bsc\\semd\\iml\\iml.huji repo\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\0erel\\onedrive\\documents\\cs.bsc\\semd\\iml\\iml.huji repo\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 328, in fit\n",
      "    X, y, multi_output=True, accept_sparse=\"csc\", dtype=DTYPE\n",
      "  File \"c:\\users\\0erel\\onedrive\\documents\\cs.bsc\\semd\\iml\\iml.huji repo\\venv\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\users\\0erel\\onedrive\\documents\\cs.bsc\\semd\\iml\\iml.huji repo\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 976, in check_X_y\n",
      "    estimator=estimator,\n",
      "  File \"c:\\users\\0erel\\onedrive\\documents\\cs.bsc\\semd\\iml\\iml.huji repo\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"c:\\users\\0erel\\onedrive\\documents\\cs.bsc\\semd\\iml\\iml.huji repo\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 116, in _assert_all_finite\n",
      "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "All estimators failed to fit",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNotFittedError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_25688\\848021872.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     24\u001B[0m         \u001B[0mcv\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m5\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparam_grid\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mparam_grid\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     25\u001B[0m \tscoring=lambda label, pred: f1_score(label, pred, labels=[0, 1],\n\u001B[1;32m---> 26\u001B[1;33m \t                                     average=\"macro\")).fit(train_X,train_y)\n\u001B[0m\u001B[0;32m     27\u001B[0m \u001B[0mcv_errors\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m1\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mrandom_forest_cv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcv_results_\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"mean_test_score\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[0mstd\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrandom_forest_cv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcv_results_\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"std_test_score\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\0erel\\onedrive\\documents\\cs.bsc\\semd\\iml\\iml.huji repo\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    889\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mresults\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    890\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 891\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_run_search\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mevaluate_candidates\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    892\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    893\u001B[0m             \u001B[1;31m# multimetric is determined here because in the case of a callable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\0erel\\onedrive\\documents\\cs.bsc\\semd\\iml\\iml.huji repo\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36m_run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1390\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_run_search\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevaluate_candidates\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1391\u001B[0m         \u001B[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1392\u001B[1;33m         \u001B[0mevaluate_candidates\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mParameterGrid\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparam_grid\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1393\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1394\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\0erel\\onedrive\\documents\\cs.bsc\\semd\\iml\\iml.huji repo\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36mevaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    873\u001B[0m                 \u001B[1;31m# of out will be done in `_insert_error_scores`.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    874\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mcallable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mscoring\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 875\u001B[1;33m                     \u001B[0m_insert_error_scores\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0merror_score\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    876\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    877\u001B[0m                 \u001B[0mall_candidate_params\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcandidate_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\0erel\\onedrive\\documents\\cs.bsc\\semd\\iml\\iml.huji repo\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001B[0m in \u001B[0;36m_insert_error_scores\u001B[1;34m(results, error_score)\u001B[0m\n\u001B[0;32m    329\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    330\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0msuccessful_score\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 331\u001B[1;33m         \u001B[1;32mraise\u001B[0m \u001B[0mNotFittedError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"All estimators failed to fit\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    332\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    333\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msuccessful_score\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdict\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNotFittedError\u001B[0m: All estimators failed to fit"
     ]
    }
   ],
   "source": [
    "import agoda_cancellation_estimator\n",
    "import importlib\n",
    "\n",
    "importlib.reload(agoda_cancellation_estimator)\n",
    "from agoda_cancellation_estimator import *\n",
    "\n",
    "train_X = design_matrix\n",
    "train_y = np.array(cancellation_labels).reshape((-1,))\n",
    "test_X = test_set\n",
    "test_y = np.array(test_set_labels).reshape((-1,))\n",
    "train_test_X = train_test_set\n",
    "train_test_y = train_test_set_labels\n",
    "\n",
    "# Fit model over data with different model seeds.\n",
    "scores1 = []\n",
    "scores2 = []\n",
    "\n",
    "param_grid = {'max_leaf_nodes': range(20, 100, 10),\n",
    "              'n_estimators': range(100, 300, 50), 'max_depth': range(5, 15)}\n",
    "\n",
    "random_forest_cv = GridSearchCV(\n",
    "\tRandomForestClassifier(random_state=1, class_weight='balanced_subsample',\n",
    "\t                       n_jobs=8),\n",
    "\tcv=5, param_grid=param_grid,\n",
    "\tscoring=lambda label, pred: f1_score(label, pred, labels=[0, 1],\n",
    "\t                                     average=\"macro\")).fit(train_X,train_y)\n",
    "cv_errors = 1 - random_forest_cv.cv_results_[\"mean_test_score\"]\n",
    "std = random_forest_cv.cv_results_[\"std_test_score\"]\n",
    "\n",
    "minimizer = np.ravel_multi_index(np.argmin(cv_errors),cv_errors.shape)\n",
    "print(cv_errors[minimizer])\n",
    "\n",
    "# for n in range(1, 20):\n",
    "# \tmodel = RandomForestClassifier(random_state=1, max_leaf_nodes=40,\n",
    "# \t                               n_estimators=200,\n",
    "# \t                               max_depth=10,\n",
    "# \t                               class_weight='balanced_subsample', n_jobs=8)\n",
    "# \t# model=GradientBoostingClassifier(n_estimators=500, learning_rate=0.1, max_features='auto', max_depth=5,\n",
    "# \t#                                  )\n",
    "# \tmodel.fit(train_X, train_y)\n",
    "# \ty_pred = model.predict(test_X)\n",
    "# \tf1 = f1_score(test_y, y_pred, labels=[0, 1], average=\"macro\")\n",
    "# \tprecision = precision_score(test_y, y_pred, labels=[0, 1],\n",
    "# \t                            average=\"macro\")\n",
    "# \trecall = recall_score(test_y, y_pred, labels=[0, 1], average=\"macro\")\n",
    "# \tprint(f\"random seed: {n}\")\n",
    "# \tprint(\n",
    "# \t\tf\"f1 score: {f1}, precision score: {precision}, recall score: {recall}.\")\n",
    "# \tprint(confusion_matrix(test_y, y_pred, labels=[0, 1]))\n",
    "# \tscores1.append(f1)\n",
    "# \ty_pred = model.predict(train_test_X)\n",
    "# \tf1 = f1_score(train_test_y, y_pred, labels=[0, 1], average=\"macro\")\n",
    "# \tprecision = precision_score(train_test_y, y_pred, labels=[0, 1],\n",
    "# \t                            average=\"macro\")\n",
    "# \trecall = recall_score(train_test_y, y_pred, labels=[0, 1], average=\"macro\")\n",
    "# \tprint(\n",
    "# \t\tf\"f1 score: {f1}, precision score: {precision}, recall score: {recall}.\")\n",
    "# \tprint(confusion_matrix(train_test_y, y_pred, labels=[0, 1]))\n",
    "# \tprint()\n",
    "# \tscores2.append(f1)\n",
    "#\n",
    "# # scores = pd.DataFrame([scores1])\n",
    "# # px.line(scores,x=scores[:,0]).show()\n",
    "# fig = go.Figure(\n",
    "# \t[go.Scatter(x=list(range(1, 20)), y=scores1, mode=\"lines+markers\")],\n",
    "# \t[go.Scatter(x=list(range(1, 20)), y=scores2, mode=\"lines+markers\")])\n",
    "# fig.update_layout(go.Layout(margin=dict(t=100)))\n",
    "# fig.show()\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}