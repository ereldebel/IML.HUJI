{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6qNJ_JSlErv"
   },
   "source": [
    "# Lab 00 - A - Data Analysis In Python - First Steps\n",
    "\n",
    "Machine learning and data analysis (that is usually also a pre-step for learning) deal with data. Thererefore we need tools to manipulate it and extract the information we want. In the Python environment there are two very useful packages for this: [`numpy`](https://numpy.org/doc/1.19/) and [`pandas`](https://pandas.pydata.org/docs/reference/index.html#api).\n",
    "\n",
    "In this lab, we will take the first steps into using these packages and see some of their functionalities. These will be needed throughout the course. Both packages contain many useful functionalities, of which we will introduce only a few. To find out more about the other functionalities, the documentations, **Google** and **StackOverflow** are your best friends. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Hx4v3hy-fnu9"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_17244\\2145739386.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0msys\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0msys\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"../\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mutils\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\OneDrive\\Documents\\CS.BSc\\SemD\\IML\\IML.HUJI repo\\utils.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;31m# Imports and settings for plotting of graphs\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mplotly\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mio\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mpio\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      7\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mplotly\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgraph_objects\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mgo\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mplotly\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msubplots\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmake_subplots\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "# Load commonly used imports (such as numpy and pandas) and several utils functions that \n",
    "# are used thoughout different labs and code examples\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asLx3ujI09-B"
   },
   "source": [
    "# Numpy - The Basics\n",
    "\n",
    "Let us start with numpy. This package supports vector, matrix and tensor operations over numerical (but not just) data. It is very comfortable and much faster than `for` loops and classic `list` manipulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fPwJrL1Bc84L"
   },
   "source": [
    "## Array Creation\n",
    "\n",
    "There are multiple ways to create an array. We can create it from an existing list, load it from a file or generate a new array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wL4cbVc-pGZ9",
    "outputId": "e5e90a34-4000-4d85-8672-7559f6ecaf6d"
   },
   "outputs": [],
   "source": [
    "array_1D = np.array([6, 2, 8, 4, 5, 10, 7, 143, 9, 10])\n",
    "print(array_1D)\n",
    "print(array_1D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gt6ZB5FG1p2d",
    "outputId": "b3f5bdbf-9547-485a-bff1-29e07aecc6aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  10   20   30   40]\n",
      " [ 100  200  300  400]\n",
      " [1000 2000 3000 4000]]\n",
      "(3, 4)\n"
     ]
    }
   ],
   "source": [
    "array_2D = np.array(\n",
    "\t[[10, 20, 30, 40],\n",
    "\t [100, 200, 300, 400],\n",
    "\t [1000, 2000, 3000, 4000]])\n",
    "print(array_2D)\n",
    "print(array_2D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ICxIiGg92M7C",
    "outputId": "5c5f5333-af82-4e07-f836-202fddf7a8fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int32'>\n",
      "[[[  10   20   30   40]\n",
      "  [ 100  200  300  400]\n",
      "  [1000 2000 3000 4000]]\n",
      "\n",
      " [[  11   21   31   41]\n",
      "  [ 101  201  301  401]\n",
      "  [1001 2001 3001 4001]]]\n",
      "(2, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "array_3D = np.array(\n",
    "\t[[[10, 20, 30, 40], [100, 200, 300, 400], [1000, 2000, 3000, 4000]],\n",
    "\t [[11, 21, 31, 41], [101, 201, 301, 401], [1001, 2001, 3001, 4001]]])\n",
    "print(type(array_3D[0][0][0]))\n",
    "print(array_3D)\n",
    "print(array_3D.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8ikdeRnpupl"
   },
   "source": [
    "Using `numpy`'s functions for creating new arrays requires specifying the shape of the desired output array. This is an n-array tuple specifying the sizes of the different dimensions. \n",
    "\n",
    "*   Specifying the shape `(3)` will create a 1D array with 3 entries.\n",
    "*   Specifying the shape `(10, 3)` will create a 2D matrix with 10 rows and 3 columns.\n",
    "*   Specifying the shape `(10, 28, 28)` will create a 3D matrix (a tensor) which we can think of in the following manner: it is an object holding 10 2D matrices of size 28x28.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iZNN-w4B2vsy",
    "outputId": "5d668f56-aae6-42cc-c13c-b6cce1b0a1bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n",
      "[[[0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]]\n",
      "\n",
      " [[0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]]\n",
      "\n",
      " [[0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]]\n",
      "\n",
      " [[0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]]]\n",
      "[[1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initalize arrays with built-in numpy functions\n",
    "zeros_3D = np.zeros((4, 5, 2))  # Create a 3D arrays of 0's\n",
    "ones_2D = np.ones((4, 5))  # Create a 2D arrays of 1's\n",
    "print(type(zeros_3D[0][0][0]))\n",
    "print(zeros_3D)\n",
    "print(ones_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ke7ltD8qt8I",
    "outputId": "9de4ca81-d090-47e7-bbad-a7cd9dea2d5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(50)  # Create the vector [0, 1, 2, 3, 4, .. , 48, 49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g8tf4cd4q4oE",
    "outputId": "91be65fe-ab25-455b-9fc8-8a455b07104c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 5, 27, 47],\n       [32, 10, 32]])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a vector of random integers from 5 to 50, with shape (2, 3)\n",
    "np.random.randint(5, 50, (2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THE5lTeTrN4w"
   },
   "source": [
    "There are many other functions such as `np.full`, `np.eye`, `np.random.uniform`, etc. Next, let us load an existsing dataset into a numpy array. This specific dataset represents images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "O3ZsPny03qmZ",
    "outputId": "3d22fab1-7cb1-4180-a1c2-a5c1528f6de5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(100, 28, 28)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array = np.loadtxt(open(\"../datasets/MNIST_Images.csv\", \"rb\"),\n",
    "\t\t\t\t\t   delimiter=\",\").reshape(-1, 28, 28)\n",
    "img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'px' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_17244\\2015531023.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mimg_array\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloadtxt\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"../datasets/MNIST_Images.csv\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"rb\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdelimiter\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\",\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m28\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m28\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mimg_array\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mpx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimshow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg_array\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'px' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "img_array = np.loadtxt(open(\"../datasets/MNIST_Images.csv\", \"rb\"),\n",
    "\t\t\t\t\t   delimiter=\",\").reshape(-1, 28, 28)\n",
    "img_array.shape\n",
    "px.imshow(img_array[0]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F10jW-AO8PdQ"
   },
   "source": [
    "## Array indexing and slicing\n",
    "\n",
    "A great strength of `numpy` is the ease in subsetting an array to retrieve only specific parts of it. We do so by indexing and slicing the arrays. For 1D arrays these operations are very similar to those over lists.  For arrays of higher dimensions, we use a comma to separate the slicing of each dimension. For example, accessing an element in the array `arr` in the first row and second column is done by: `arr[0, 1]` (recall indexing in python begins from zero). To select only the second column, over all rows write: `arr[:, 2]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KZJfKZ-_67Yk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "array_1D = np.array([10, 11, 12, 13, 14, 15, 16])\n",
    "# Select 1st element\n",
    "print(\"Select 1st element\")\n",
    "print(array_1D[1])\n",
    "\n",
    "# Select all the elements from 1st to 4th element\n",
    "print(\"\\nSelect all the elements from 1st to 4th element\")\n",
    "print(array_1D[1:5])\n",
    "\n",
    "# Select elements [1, 4]\n",
    "print(\"\\nSelect elements [1, 4]\")\n",
    "print(array_1D[[1, 4]])\n",
    "print()\n",
    "\n",
    "array_2D = np.array([[1, 2, 3, 4],\n",
    "\t\t\t\t\t [5, 6, 7, 8],\n",
    "\t\t\t\t\t [9, 10, 11, 12],\n",
    "\t\t\t\t\t [13, 14, 15, 16],\n",
    "\t\t\t\t\t [17, 18, 19, 20]])\n",
    "# Select 1st row, 2nd column  \n",
    "print(array_2D[1, 2])\n",
    "\n",
    "randint_2D = np.random.randint(5, 50, (10, 20))\n",
    "print(\"\\nPrint random array\")\n",
    "print(randint_2D)\n",
    "\n",
    "# Select from 3rd row to 5th, all the columns\n",
    "print(\"\\nSelect from 3rd row to 5th, all the columns\")\n",
    "print(randint_2D[2:5, :])\n",
    "\n",
    "# Select from 3rd row to 5th, columns 1 and 2\n",
    "print(\"\\nSelect from 3rd row to 5th, columns 1 and 2\")\n",
    "print(randint_2D[2:5, 1:3])\n",
    "\n",
    "# Select from 3d row to 5th, columns 3, 5, 6, and  11\n",
    "print(\"\\nSelect from 3rd row to 5th, columns 3, 5, 6, and  11\")\n",
    "print(randint_2D[2:5, [3, 5, 6, 11]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kn4PwoBerrJl"
   },
   "source": [
    "## Matrix Operations\n",
    "Another strength of the `numpy` package is that all matrix operations you can think of (and even more) are already implemented. For example, element-wise addition of scalar, multiplication, powering up a matrix, log-transformations and much more.\n",
    "\n",
    "As `numpy` overloads the different mathematical operators, it is easy to write mathematical expressions over 2 (or more) vectors/matrices, such as summing or multiplying and also comparing their elements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N4OXpnPKiLbg",
    "outputId": "9d066e26-47b4-4db3-971d-5e3c4ae6a1d0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Operations on 1 matrix\n",
    "A = np.arange(1, 33).reshape(4,\n",
    "\t\t\t\t\t\t\t 8)  # Create an array of numbers from 1 ot 32, and then make a 2d array of 4 rows to 8 columns\n",
    "print(A)\n",
    "\n",
    "print(\"\\n\\nA + 1:\")\n",
    "print(A + 1)\n",
    "print(\"\\n2 * A:\")\n",
    "print(2 * A)\n",
    "print(\"\\nA*A*A:\")\n",
    "print(np.power(A, 3))\n",
    "print(\"\\nlog(A):\")\n",
    "print(np.log(A))\n",
    "print(\"\\nA Transpose:\")\n",
    "print(A.transpose())  # also np.transpose(A) and A.T are valid syntaxes\n",
    "print(\"\\n A > 10:\")\n",
    "print(A > 10)\n",
    "\n",
    "# Operations on 2 matrices\n",
    "A = np.arange(6).reshape([2, 3])\n",
    "B = np.random.randint(1, 10, (2, 3))\n",
    "print(\"A\")\n",
    "print(A)\n",
    "print(\"\\n\\nB\")\n",
    "print(B)\n",
    "\n",
    "print(\"\\nA+B:\")\n",
    "print(A + B)  # Equivalent to np.add(a_array, b_array)\n",
    "print(\"\\n A * B (element-wise multiplication):\")\n",
    "print(np.multiply(A, B))\n",
    "print(\"\\n AB (matrix multiplication):\")\n",
    "print(A @ B.T)  # Equivalent to np.dot(a_array, b_array)\n",
    "\n",
    "print(\"\\nA > B\")\n",
    "print(A > B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBGJkM0PvWPC"
   },
   "source": [
    "For many `numpy` operations we can specify the `axis` over which to perform the operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gXznlk6aiNP3",
    "outputId": "09591fed-8ec1-44b6-e98e-af7ca2e0824e"
   },
   "outputs": [],
   "source": [
    "# Concatenate matrices\n",
    "print(\"\\nConcatenate 2 arrays by the rows:\")\n",
    "print(np.concatenate((A, B), axis=0))  # Concatenate rows - look at the shape\n",
    "print(\"\\nConcatenate 2 arrays by the columns:\")\n",
    "print(\n",
    "\tnp.concatenate((A, B), axis=1))  # Concatenate columns - look at the shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4O_Kvftueqx"
   },
   "source": [
    "##  Basic Statistics\n",
    "\n",
    "You can easily calculate a lot of basic statistics from an array, such as the sum, mean, variance, maximum, argmax, etc. All of these can be retrieved either over the entire array or over rows/columns.\n",
    "\n",
    "For each of these functions, you can get the statistic for: \n",
    "- the whole array: `np.stat(arr)`\n",
    "- by row: `np.stat(arr, axis = 1)`\n",
    "- by column: `np.stat(arr, axis = 0)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2JhB4W8F_gdp"
   },
   "outputs": [],
   "source": [
    "# Basic statistics of a matrix\n",
    "A = np.arange(6).reshape([2, 3])\n",
    "print(\"A\")\n",
    "print(A)\n",
    "\n",
    "print(\"\\n\\nSum of the array\")\n",
    "print(np.sum(A))  # Sum all the matrix (return a scalar)\n",
    "print(\"\\nSum of the array by column\")\n",
    "print(np.sum(A, axis=0))  # Sum by column (return a vector)\n",
    "print(\"\\nSum of the array by row\")\n",
    "print(np.sum(A, axis=1))  # Sum by row (return a vector)\n",
    "\n",
    "print(\"\\nMax of each row\")\n",
    "print(np.max(A, axis=1))  # Max by column (return a vector)\n",
    "\n",
    "print(\"\\nMax of each column\")\n",
    "print(np.max(A, axis=0))  # Max by row (return a vector)\n",
    "\n",
    "print(\"\\nAverage of all the array\")\n",
    "print(np.mean(A))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qfF-hmlYw2fL"
   },
   "source": [
    "## Sampling From Distributions\n",
    "\n",
    "`numpy` provides a broad set of distributions to sample from. We will cover this in more depth in lab 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y2HOVVWZw1vo",
    "outputId": "131b66b9-cb51-4c99-cfb9-be294c1cdf18"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.random.randint(1, 15, size=20)\n",
    "print(\"A\")\n",
    "print(A)\n",
    "\n",
    "print(\"\\n\\nThe values that appear in the array\")\n",
    "print(np.unique(A))\n",
    "print(\"\\nHow many values are between [0, 5), [5, 10), [10, 15]\")\n",
    "print(np.histogram(A, bins=[0, 5, 10, 15]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOzh7VvbzFcJ"
   },
   "source": [
    "## Linear Algebra\n",
    "One of the most important mathematical fields in machine learning is linear algebra. You can perform many of these operations using `numpy`. You can calculate the eigenvectors of a matrix, or its inverse, the rank of the matrix and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57F3_BlBR-R3",
    "outputId": "a5c64b69-da33-451b-f54d-940f46c40cc0"
   },
   "outputs": [],
   "source": [
    "A = np.array([[1., 2.], [3., 4.]])\n",
    "print(\"A\")\n",
    "print(A)\n",
    "print(\"\\n\\nInverse of A\")\n",
    "print(np.linalg.inv(A))\n",
    "\n",
    "B = np.diag((1, 2, 3))\n",
    "print(\"\\n\\nB\")\n",
    "print(B)\n",
    "\n",
    "eigvalues, eigvectors = np.linalg.eig(B)\n",
    "print(\"\\neigenvalues, eigenvectors\")\n",
    "print(eigvalues, eigvectors)\n",
    "\n",
    "print(\"\\nRank of the matrix\")\n",
    "print(np.linalg.matrix_rank(B))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mLWs10U0dxW"
   },
   "source": [
    "## Reshaping\n",
    "\n",
    "You can change the shape of your array, with transpose, flattening, reshape, \n",
    "adding a new axis (see `np.newaxis`)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qImJs4njAm43",
    "outputId": "3e70fefb-41fa-4c1c-d40e-1e1bb68e2590"
   },
   "outputs": [],
   "source": [
    "B = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "print(\"\\n\\nB\")\n",
    "print(B)\n",
    "\n",
    "print(\"\\nFlatten matrix\")\n",
    "print(np.ravel(B))\n",
    "\n",
    "print(\"\\nTranspose matrix\")\n",
    "print(B.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OwjDVpmk1Obt"
   },
   "source": [
    "## Sorting\n",
    "\n",
    "You can sort the matrix by row or by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F7oe-5W4Vf2C"
   },
   "outputs": [],
   "source": [
    "B = np.array([[3, 6, 1, 4, 10], [5, 1, 8, 3, 65]])\n",
    "\n",
    "print(\"B\")\n",
    "print(B)\n",
    "\n",
    "print(\"\\n\\nSort by row\")\n",
    "print(np.sort(B, axis=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCsGskFR14ff"
   },
   "source": [
    "## Indexing By Condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YSIflm-x13uf",
    "outputId": "6790bea5-8076-416c-a327-68ec2ad1c882"
   },
   "outputs": [],
   "source": [
    "A = np.random.randint(1, 30, (5, 4))\n",
    "print(\"A\")\n",
    "print(A)\n",
    "\n",
    "print(\"\\nGet the numbers that are greater than 5:\")\n",
    "print(A[A > 5])\n",
    "\n",
    "print(\"\\nGet the numbers that are divisible by 4:\")\n",
    "print(np.extract(np.mod(A, 4) == 0, A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZHrvwPc3xHl"
   },
   "source": [
    "## Let's practice!\n",
    "\n",
    "To get you a bit more accustomed to `numpy` you are encouraged to solve the following challenges. If you choose to not solve the following challenges, be sure to understand the solutions. Do not use loops or list comprehensions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7IjEOuKwxbp"
   },
   "source": [
    "\n",
    "Write a program to create a `7x10` matrix that has `0` and `1` staggered:\n",
    "```\n",
    "# 0 1 0 1 0 1 0\n",
    "# 1 0 1 0 1 0 1\n",
    "# 0 1 0 1 0 1 0\n",
    "# 1 0 1 0 1 0 1\n",
    "```\n",
    "Hint: use slice operations on different axes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_rAGqr2eknl"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.zeros((7, 10))\n",
    "A[::2, ::2] = 1\n",
    "A[1::2, 1::2] = 1\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQdwsu47y0_u"
   },
   "source": [
    "Calculate the volume of a cylinder with the following diameters and lengths:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bNPOP0jU2On0"
   },
   "outputs": [],
   "source": [
    "diameters = np.array([1, 3, 5, 2, 4])\n",
    "lengths = np.array([10, 20, 3, 10, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C23xh9uX6Sbj"
   },
   "outputs": [],
   "source": [
    "print(np.array(np.power(diameters / 2, 2) * lengths * np.pi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2RXomvKz1E2"
   },
   "source": [
    "Write a function that receives 2 vectors and returns their cartesian product:\n",
    "```\n",
    "def create_cartesian_product(vec1, vec2):\n",
    "  pass\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sqo0fuvPmlsM"
   },
   "outputs": [],
   "source": [
    "def cartesian_product(vec1, vec2):\n",
    "\t# np.repeat([1, 2, 3], 4) -> [1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3]\n",
    "\t# np.tile([1, 2, 3], 4)   -> [1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3]\n",
    "\treturn np.array(\n",
    "\t\t(np.repeat(vec1, len(vec2)), np.tile(vec2, len(vec1)))).transpose()\n",
    "\n",
    "\n",
    "print(cartesian_product([1, 2, 3], [4, 5, 6, 7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fmVsBdq04UL"
   },
   "source": [
    "Given an array `a` and a number `n`, find the closest number to `n` in `a`:\n",
    "```\n",
    "def find_closest(a, n):\n",
    "  pass\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8dipzX5I8AE-"
   },
   "outputs": [],
   "source": [
    "def find_closest(a, n):\n",
    "\ta = np.array(a)\n",
    "\treturn a[np.argmin(np.abs(a - n))]\n",
    "\n",
    "\n",
    "print(find_closest([1, 24, 12, 13, 14], 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_PKVyGO2dov"
   },
   "source": [
    "Check if the sudoku grid is valid:\n",
    "*   Check that each row contains all the numbers from 1 to 9\n",
    "*   Check that each column contains all the numbers from 1 to 9\n",
    "*   Check that each of the 9 non-overlapping `3x3` blocks composing grid contain 1 to 9\n",
    "\n",
    "You can assume it contains only integers and that the shape of the array is `9x9`\n",
    "```\n",
    "def check_sudoku(grid):\n",
    "  pass\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZ5WPLiagvSI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def cartesian_product(vec1, vec2):\n",
    "\t# np.repeat([1, 2, 3], 4) -> [1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3]\n",
    "\t# np.tile([1, 2, 3], 4)   -> [1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3]\n",
    "\treturn np.array(\n",
    "\t\t(np.repeat(vec1, len(vec2)), np.tile(vec2, len(vec1)))).transpose()\n",
    "\n",
    "\n",
    "def is_1_to_9(array):\n",
    "\treturn np.all(np.sort(array) == np.arange(1, 10))\n",
    "\n",
    "\n",
    "def check_sudoku(grid):\n",
    "\tdef check_block(block):\n",
    "\t\treturn is_1_to_9(np.ravel(grid[block[0] * 3:block[0] * 3 + 3],\n",
    "\t\t\t\t\t\t\t\t  grid[block[1] * 3:block[1] * 3 + 3]))\n",
    "\n",
    "\tif not is_1_to_9(np.unique(grid)):\n",
    "\t\treturn False\n",
    "\tif not np.all(np.apply_along_axis(is_1_to_9, 0, grid)):\n",
    "\t\treturn False\n",
    "\tif not np.all(np.apply_along_axis(is_1_to_9, 1, grid)):\n",
    "\t\treturn False\n",
    "\treturn np.all(np.apply_along_axis(check_block, 0,\n",
    "\t\t\t\t\t\t\t\t\t  cartesian_product([0, 1, 2], [0, 1, 2])))\n",
    "\n",
    "\n",
    "assert check_sudoku(np.tile(np.arange(1, 10), 9).reshape((9, 9))) == False\n",
    "assert check_sudoku(np.tile(np.arange(1, 10), 9).reshape((9, 9))) == True\n",
    "\n",
    "\n",
    "# def is_1_to_9(array_):\n",
    "#   # Return True if the array contains all the numbers from 1 to 9, False otherwise\n",
    "#     return np.all(np.sort(array_, axis = None) == np.arange(1, 10))\n",
    "\n",
    "# def check_sudoku(grid):\n",
    "#     def check_block(coords_block):\n",
    "#         return is_1_to_9(grid[coords_block[0]*3 : coords_block[0]*3+3, \n",
    "#                               coords_block[1]*3 : coords_block[1]*3+3])\n",
    "\n",
    "#     grid = np.array(grid)\n",
    "\n",
    "#     # Check that the grid contains only 1 to 9\n",
    "#     if (not is_1_to_9(np.unique(grid))):\n",
    "#         return False\n",
    "\n",
    "#     # Check that each line/column contains 1 to 9:\n",
    "#     # Sort each column. We expect it to be\n",
    "#     # [[1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 2, 2, 2, 2, 2, 2, 2] ... [9, 9, 9, 9, 9, 9, 9, 9, 9]]\n",
    "#     # Thus we expect the sums of the rows: 1*9, 2*9....\n",
    "#     if  np.any(np.sum(np.sort(grid, axis = 0), axis = 1) != np.arange(1, 10)*9):\n",
    "#         return False\n",
    "\n",
    "#     # Make the same for the columns\n",
    "#     if np.any(np.sum(np.sort(grid.transpose(), axis = 0), axis = 1) != np.arange(1, 10)*9):\n",
    "#         return False\n",
    "\n",
    "\n",
    "#     # 0,0 0,0 0,0    0,1 0,1 0,1    0,2 0,2 0,2\n",
    "#     # 0,0 0,0 0,0    0,1 0,1 0,1    0,2 0,2 0,2\n",
    "#     # 0,0 0,0 0,0    0,1 0,1 0,1    0,2 0,2 0,2\n",
    "#     #\n",
    "#     #\n",
    "#     # 1,0 1,0 1,0    1,1 1,1 1,1    1,2 1,2 1,2\n",
    "#     # 1,0 1,0 1,0    1,1 1,1 1,1    1,2 1,2 1,2\n",
    "#     # 1,0 1,0 1,0    1,1 1,1 1,1    1,2 1,2 1,2\n",
    "#     #\n",
    "#     #\n",
    "#     # 2,0 2,0 2,0    2,1 2,1 2,1    2,2 2,2 2,2\n",
    "#     # 2,0 2,0 2,0    2,1 2,1 2,1    2,2 2,2 2,2\n",
    "#     # 2,0 2,0 2,0    2,1 2,1 2,1    2,2 2,2 2,2\n",
    "\n",
    "\n",
    "#     # For each block of 9, check if it contains all the numbers 1 to 9\n",
    "#     blocks_are_valid = np.apply_along_axis(check_block, 1, cartesian_product([0, 1, 2], [0, 1, 2]))\n",
    "#     return np.all(blocks_are_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmF3gn_pmP5X"
   },
   "source": [
    "Given a matrix, check if some row is a scalar multplication of another\n",
    "```\n",
    "def check_dependencies(matrix_):\n",
    "  pass\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IOxhEqkmhsRS"
   },
   "outputs": [],
   "source": [
    "def check_dependencies(matrix_):\n",
    "\tmatrix = np.array(matrix_)\n",
    "\n",
    "\tdef rows_are_dependent(indices):\n",
    "\t\tif indices[0] == indices[1]:\n",
    "\t\t\treturn False\n",
    "\t\treturn np.unique(matrix[indices[0],] / matrix[indices[1],]).shape[\n",
    "\t\t\t\t   0] == 1\n",
    "\n",
    "\treturn np.any(np.apply_along_axis(rows_are_dependent, 1, cartesian_product(\n",
    "\t\tnp.arange(matrix.shape[0]), np.arange(matrix.shape[0]))))\n",
    "\n",
    "# def check_dependencies(matrix_):\n",
    "#     def rows_are_dependent(indices):\n",
    "#         if indices[0] == indices[1]:\n",
    "#             return False\n",
    "#         return np.unique(matrix_[indices[0],] / matrix_[indices[1],]).shape[0] == 1\n",
    "#\n",
    "#     return np.any(np.apply_along_axis(rows_are_dependent, 1,\n",
    "#                                       cartesian_product(np.arange(matrix_.shape[0]), np.arange(matrix_.shape[0]))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwL7kvvTkkxb"
   },
   "source": [
    "Write a function that gets a 1D array and check if there is no local extrema point in addition to the global one.\n",
    "```\n",
    "def have_an_extrema(array):\n",
    "  pass\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jg12aIuikhh3"
   },
   "outputs": [],
   "source": [
    "def have_a_maxima(array):\n",
    "\targmax_arr = np.argmax(array[1:-1]) + 1\n",
    "\tbefore_max_neg = np.all(array[:argmax_arr - 1] - array[1:argmax_arr] < 0)\n",
    "\tafter_max_neg = np.all(array[argmax_arr:-1] - array[argmax_arr + 1:] > 0)\n",
    "\treturn before_max_neg and after_max_neg\n",
    "\n",
    "\n",
    "def have_an_extrema(array):\n",
    "\t# Check if it is a monotonic series\n",
    "\tif np.unique(array[:-1] - array[1:]).shape[0] == 1: return True\n",
    "\n",
    "\t# If there is a minimum, we can look for a maximum in the negated array\n",
    "\treturn have_a_maxima(array) or have_a_maxima(-array)\n",
    "\n",
    "\n",
    "have_an_extrema(np.array([1, 2, 4, 5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cf0Y2F8SlK6W"
   },
   "source": [
    "Note that instead of `array[:argmax_arr - 1] - array[1:argmax_arr]`, you could use the `np.diff` function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1S1Z7cE0E_l"
   },
   "source": [
    "# Pandas\n",
    "Until now, we have only looked at numerical data. But in real-world problems, we also have textual and categorical data. To manipulate this type of data, we will use the `pandas` library. One of the basic data structures of `pandas` is called a `DataFrame`. Generally, in a `DataFrame`, each row is a different sample and each column is a feature.\n",
    "\n",
    "For example, each row can represent a student, with columns of the ID, birthday, and gender of the student. \n",
    "\n",
    "`pandas` has a lot of possibilities of which we are going to introduce a very small subset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JGYcSz82Viq"
   },
   "source": [
    "## Array Creation\n",
    "\n",
    "In addition to creating an array from lists or randomly generated data frames, we are going to use an existing dataset of house prices (you will get back to this dataset in excercise 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8pjllLVn1qGW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data?select=train.csv\n",
    "df = pd.read_csv('../datasets/house_train.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LZZwdRpn6FIf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../datasets/house_train.csv', index_col=0)\n",
    "print(\"\\nRows Names\")\n",
    "print(df.index)\n",
    "print(\"\\nColumns Names\")\n",
    "print(df.columns)\n",
    "print(\"\\nDf train shape\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECFka5mE49Qo"
   },
   "source": [
    "## Indexing And Slicing\n",
    "Just like when using `numpy` you can select a subset of rows and columns. You can do it using indices or using names of the rows and columns. You can easily add a new column based on existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "svkkCAff6sYZ"
   },
   "outputs": [],
   "source": [
    "print(\"\\ndf[['GrLivArea', 'SalePrice', 'BedroomAbvGr']]\")\n",
    "print(df[['GrLivArea', 'SalePrice',\n",
    "\t\t  'BedroomAbvGr']])  # Select  GrLivArea columns SalePrice BedroomAbvGr\n",
    "\n",
    "print(\"\\ndf.loc[3:10,['GrLivArea', 'SalePrice', 'BedroomAbvGr'] ]\")\n",
    "print(df.loc[3:10, ['GrLivArea', 'SalePrice', 'BedroomAbvGr']])\n",
    "\n",
    "print(\"\\ndf.iloc[[3, 4, 5]]\")\n",
    "print(df.iloc[[3, 4, 5]])\n",
    "print(\"\\ndf.iloc[3:10,[6, 7, 8]]\")\n",
    "print(df.iloc[3:10, [6, 7, 8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "qkqshRV-No7E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Individual DF\n",
      "          ID    Height     Weight        BMI\n",
      "0  2842094.0  1.531202  79.570048  33.937871\n",
      "1  2161531.0  1.504826  56.477663  24.940434\n",
      "2  2923105.0  1.638746  60.400530  22.491462\n",
      "3  2759674.0  1.694881  51.457710  17.913154\n",
      "4  2150595.0  1.540998  89.748243  37.793890\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "individual_df = pd.DataFrame(np.array([np.random.randint(2000000, 3000000, 50),\n",
    "\t\t\t\t\t\t\t\t\t   np.random.uniform(1.50, 1.70, size=50),\n",
    "\t\t\t\t\t\t\t\t\t   np.random.uniform(45, 90,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t size=50)]).transpose(),\n",
    "\t\t\t\t\t\t\t columns=['ID', 'Height', 'Weight'])\n",
    "\n",
    "individual_df[\"BMI\"] = individual_df[\"Weight\"] / individual_df[\"Height\"].pow(2)\n",
    "print(\"\\nIndividual DF\")\n",
    "print(individual_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eyo4hxsp5TKm"
   },
   "source": [
    "# Basic Statistics\n",
    "`pandas` provides different statistical functions over `DataFrame`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Ho-eBIBt9FQI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Median of the SalePrice column\n",
      "163000.0\n",
      "\n",
      "Selecting rows by condition\n",
      "    MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "Id                                                                    \n",
      "1           60       RL         65.0     8450   Pave   NaN      Reg   \n",
      "2           20       RL         80.0     9600   Pave   NaN      Reg   \n",
      "3           60       RL         68.0    11250   Pave   NaN      IR1   \n",
      "5           60       RL         84.0    14260   Pave   NaN      IR1   \n",
      "7           20       RL         75.0    10084   Pave   NaN      Reg   \n",
      "\n",
      "   LandContour Utilities LotConfig  ... PoolArea PoolQC Fence MiscFeature  \\\n",
      "Id                                  ...                                     \n",
      "1          Lvl    AllPub    Inside  ...        0    NaN   NaN         NaN   \n",
      "2          Lvl    AllPub       FR2  ...        0    NaN   NaN         NaN   \n",
      "3          Lvl    AllPub    Inside  ...        0    NaN   NaN         NaN   \n",
      "5          Lvl    AllPub       FR2  ...        0    NaN   NaN         NaN   \n",
      "7          Lvl    AllPub    Inside  ...        0    NaN   NaN         NaN   \n",
      "\n",
      "   MiscVal MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
      "Id                                                             \n",
      "1        0      2    2008        WD         Normal     208500  \n",
      "2        0      5    2007        WD         Normal     181500  \n",
      "3        0      9    2008        WD         Normal     223500  \n",
      "5        0     12    2008        WD         Normal     250000  \n",
      "7        0      8    2007        WD         Normal     307000  \n",
      "\n",
      "[5 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../datasets/house_train.csv', index_col=0)\n",
    "print(\"\\nMedian of the SalePrice column\")\n",
    "print(df.SalePrice.median())\n",
    "\n",
    "print(\"\\nSelecting rows by condition\")\n",
    "median_price = df.SalePrice.median()\n",
    "print(df[df.SalePrice > median_price].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8lEIqi8CDNk"
   },
   "source": [
    "## Group-by\n",
    "\n",
    "When working with data that contains also a categorical feature, we are often interested in performing some kind of calculation over all rows containing the same categorical value. For example, given a data frame of student grades for different courses, we can calculate the students' average grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "tvip9jGT-Oh8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Students df\n",
      "     Name         Course  Grade\n",
      "0   Zohar  Probabilistic     92\n",
      "1  Shelly       Linearit     98\n",
      "2  Shelly          Intro     90\n",
      "3     Avi           Infi     94\n",
      "4  Shelly       Linearit    100\n",
      "\n",
      "\n",
      "Calculate average by student and by course\n",
      "      Name         Course      Grade\n",
      "0      Avi           Infi  91.400000\n",
      "1      Avi          Intro  89.000000\n",
      "2      Avi       Linearit  86.833333\n",
      "3      Avi  Probabilistic  95.000000\n",
      "4     Omer           Infi  89.750000\n",
      "5     Omer          Intro  83.000000\n",
      "6     Omer       Linearit  92.000000\n",
      "7     Omer  Probabilistic  89.500000\n",
      "8   Shelly           Infi  84.500000\n",
      "9   Shelly          Intro  89.500000\n",
      "10  Shelly       Linearit  98.200000\n",
      "11  Shelly  Probabilistic  91.000000\n",
      "12   Zohar           Infi  87.333333\n",
      "13   Zohar          Intro  88.250000\n",
      "14   Zohar       Linearit  96.000000\n",
      "15   Zohar  Probabilistic  91.166667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "students_df = pd.DataFrame(np.array(\n",
    "\t[np.random.choice([\"Zohar\", \"Shelly\", \"Omer\", \"Avi\"], 50),\n",
    "\t np.random.choice([\"Linearit\", \"Intro\", \"Infi\", \"Probabilistic\"], 50),\n",
    "\t np.random.randint(80, 101, 50)]).transpose(),\n",
    "\t\t\t\t\t\t   columns=['Name', 'Course', 'Grade'])\n",
    "students_df[\"Grade\"] = students_df[\"Grade\"].astype(int)\n",
    "\n",
    "print(\"\\n\\nStudents df\")\n",
    "print(students_df.head())\n",
    "\n",
    "print(\"\\n\\nCalculate average by student and by course\")\n",
    "print(students_df.groupby(['Name', 'Course']).mean().reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEFa78RCK1rq"
   },
   "source": [
    "## Sorting\n",
    "As in `numpy` you can sort data frame based on a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "HjdZsJab-Z3J"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      Name         Course  Grade\n4   Shelly       Linearit    100\n39  Shelly       Linearit    100\n38   Zohar  Probabilistic     99\n40  Shelly       Linearit     99\n9      Avi  Probabilistic     99",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Course</th>\n      <th>Grade</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>Shelly</td>\n      <td>Linearit</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>Shelly</td>\n      <td>Linearit</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>Zohar</td>\n      <td>Probabilistic</td>\n      <td>99</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>Shelly</td>\n      <td>Linearit</td>\n      <td>99</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Avi</td>\n      <td>Probabilistic</td>\n      <td>99</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students_df.sort_values(ascending=False, by='Grade').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4CjuO2e5LdLD"
   },
   "source": [
    "## Executing Functions By Columns\n",
    "\n",
    "In `pandas`, you can select columns and apply functions to them. You also can apply functions by elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "kkRzYW7Jm1Ay"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "df\n",
      "   col1  col2  col3\n",
      "0     7     4     8\n",
      "1     9     6     7\n",
      "2     8     5     2\n",
      "3     7     1     1\n",
      "4     4     4     2\n",
      "\n",
      "Calculate the difference between the min and the max of each column\n",
      "col1    5\n",
      "col2    5\n",
      "col3    7\n",
      "dtype: int32\n",
      "\n",
      "Multiply elements by 100\n",
      "   col1  col2  col3\n",
      "0   700   400   800\n",
      "1   900   600   700\n",
      "2   800   500   200\n",
      "3   700   100   100\n",
      "4   400   400   200\n",
      "\n",
      "\n",
      "Iterate over the columns\n",
      "\n",
      "-----------------------\n",
      "col1 0    7\n",
      "1    9\n",
      "2    8\n",
      "3    7\n",
      "4    4\n",
      "Name: col1, dtype: int32\n",
      "col2 0    4\n",
      "1    6\n",
      "2    5\n",
      "3    1\n",
      "4    4\n",
      "Name: col2, dtype: int32\n",
      "col3 0    8\n",
      "1    7\n",
      "2    2\n",
      "3    1\n",
      "4    2\n",
      "Name: col3, dtype: int32\n",
      "\n",
      "\n",
      "Iterate over the rows\n",
      "\n",
      "-----------------------\n",
      "0 col1    7\n",
      "col2    4\n",
      "col3    8\n",
      "Name: 0, dtype: int32\n",
      "1 col1    9\n",
      "col2    6\n",
      "col3    7\n",
      "Name: 1, dtype: int32\n",
      "2 col1    8\n",
      "col2    5\n",
      "col3    2\n",
      "Name: 2, dtype: int32\n",
      "3 col1    7\n",
      "col2    1\n",
      "col3    1\n",
      "Name: 3, dtype: int32\n",
      "4 col1    4\n",
      "col2    4\n",
      "col3    2\n",
      "Name: 4, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randint(1, 10, (5, 3)),\n",
    "\t\t\t\t  columns=['col1', 'col2', 'col3'])\n",
    "\n",
    "print(\"\\n\\ndf\")\n",
    "print(df)\n",
    "print(\"\\nCalculate the difference between the min and the max of each column\")\n",
    "print(df.apply(lambda x: x.max() - x.min()))\n",
    "\n",
    "# Apply by element\n",
    "print(\"\\nMultiply elements by 100\")\n",
    "print(df.applymap(lambda x: x * 100))\n",
    "\n",
    "print(\"\\n\\nIterate over the columns\")\n",
    "print(\"\\n-----------------------\")\n",
    "for key, value in df.iteritems():\n",
    "\tprint(key, value)\n",
    "\n",
    "print(\"\\n\\nIterate over the rows\")\n",
    "print(\"\\n-----------------------\")\n",
    "for row_idx, row in df.iterrows():\n",
    "\tprint(row_idx, row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvuu9aP6Ib-G"
   },
   "source": [
    "## Merging Data Frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "51qFkcXH9c7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "df1\n",
      "          ID     name gender\n",
      "0  336097897     Amos      M\n",
      "1   32109678     Eran      M\n",
      "2   25976389    Sapir      F\n",
      "3   32438509  Amichai      M\n",
      "4   36790307    Hadar      F\n",
      "\n",
      "df2\n",
      "          ID     name gender\n",
      "0   21370565    Matan      M\n",
      "1   34256798  Gabriel      M\n",
      "2    3908412    Anael      F\n",
      "3  326780578    Liora      F\n",
      "\n",
      "\n",
      "Join the two dataframes along rows:\n",
      "          ID     name gender\n",
      "0  336097897     Amos      M\n",
      "1   32109678     Eran      M\n",
      "2   25976389    Sapir      F\n",
      "3   32438509  Amichai      M\n",
      "4   36790307    Hadar      F\n",
      "0   21370565    Matan      M\n",
      "1   34256798  Gabriel      M\n",
      "2    3908412    Anael      F\n",
      "3  326780578    Liora      F\n"
     ]
    }
   ],
   "source": [
    "# Concatenate data frames\n",
    "import pandas as pd\n",
    "\n",
    "# Create 2 data frames\n",
    "ids_df1 = pd.DataFrame({\n",
    "\t'ID': ['336097897', '32109678', '25976389', '32438509', '36790307'],\n",
    "\t'name': ['Amos', 'Eran', 'Sapir', 'Amichai', 'Hadar'],\n",
    "\t'gender': [\"M\", \"M\", \"F\", \"M\", \"F\"]})\n",
    "\n",
    "ids_df2 = pd.DataFrame({\n",
    "\t'ID': ['21370565', '34256798', '3908412', '326780578'],\n",
    "\t'name': ['Matan', 'Gabriel', 'Anael', 'Liora'],\n",
    "\t'gender': [\"M\", \"M\", \"F\", \"F\"]})\n",
    "\n",
    "print(\"\\n\\ndf1\")\n",
    "print(ids_df1)\n",
    "print(\"\\ndf2\")\n",
    "print(ids_df2)\n",
    "print(\"\\n\\nJoin the two dataframes along rows:\")\n",
    "concatenate_data = pd.concat([ids_df1, ids_df2])\n",
    "print(concatenate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now join the result_data and df_exam_data along ID:\n"
     ]
    },
    {
     "data": {
      "text/plain": "          ID     name gender  birth_year\n0  336097897     Amos      M        1995\n1   32109678     Eran      M        1996\n2   25976389    Sapir      F        1993\n3   32438509  Amichai      M        1994\n4   36790307    Hadar      F        1997\n5   21370565    Matan      M        1991\n6   34256798  Gabriel      M        1994\n7    3908412    Anael      F        1992\n8  326780578    Liora      F        1996",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>name</th>\n      <th>gender</th>\n      <th>birth_year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>336097897</td>\n      <td>Amos</td>\n      <td>M</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>32109678</td>\n      <td>Eran</td>\n      <td>M</td>\n      <td>1996</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>25976389</td>\n      <td>Sapir</td>\n      <td>F</td>\n      <td>1993</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>32438509</td>\n      <td>Amichai</td>\n      <td>M</td>\n      <td>1994</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>36790307</td>\n      <td>Hadar</td>\n      <td>F</td>\n      <td>1997</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>21370565</td>\n      <td>Matan</td>\n      <td>M</td>\n      <td>1991</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>34256798</td>\n      <td>Gabriel</td>\n      <td>M</td>\n      <td>1994</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3908412</td>\n      <td>Anael</td>\n      <td>F</td>\n      <td>1992</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>326780578</td>\n      <td>Liora</td>\n      <td>F</td>\n      <td>1996</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birthdates_id = pd.DataFrame({\n",
    "\t'ID': ['336097897', '32109678', '25976389', '32438509', '36790307',\n",
    "\t\t   '21370565', '34256798', '3908412', '326780578'],\n",
    "\t'birth_year': [1995, 1996, 1993, 1994, 1997, 1991, 1994, 1992, 1996]})\n",
    "\n",
    "print(\"\\nNow join the result_data and df_exam_data along ID:\")\n",
    "pd.merge(concatenate_data, birthdates_id, on='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4N-gAa7bcLp5"
   },
   "source": [
    "## Let's Practice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HflHhEFaP5ya"
   },
   "source": [
    "Let us create a table of flight companies' flights. Each row will represent a single flight and will have 3 features: city of departure, city of destination and price. \n",
    "\n",
    "Implement a function `create_flight_df` that recieves a collection of cities and creates a dataset of randomly selected flights and a price in the range of 100-400.\n",
    "\n",
    "```\n",
    "    def create_flight_df(cities_poss, nrows = 100):\n",
    "        pass\n",
    "```\n",
    "\n",
    "The output data frame must not have more than a single record for any pair of cities. There are no flights from a city to itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "KWY63-sATsr9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  Departure Destination Price\n0   Nairobi    Kinshasa   170\n1  New-York        Lima   343\n2  Santiago   Singapore   122\n3      Lima      London   113\n4      Lima       Seoul   297",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Departure</th>\n      <th>Destination</th>\n      <th>Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Nairobi</td>\n      <td>Kinshasa</td>\n      <td>170</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>New-York</td>\n      <td>Lima</td>\n      <td>343</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Santiago</td>\n      <td>Singapore</td>\n      <td>122</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Lima</td>\n      <td>London</td>\n      <td>113</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Lima</td>\n      <td>Seoul</td>\n      <td>297</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def create_flight_df(cities, nrows=20):\n",
    "\tdf = pd.DataFrame([], columns=[\"Departure\", \"Destination\", \"Price\"])\n",
    "\n",
    "\twhile df.shape[0] < nrows:\n",
    "\t\tdep, dest = np.random.choice(cities, size=2, replace=False)\n",
    "\t\tprice = np.random.randint(100, 400)\n",
    "\n",
    "\t\tif not ((df[\"Departure\"] == dep) & (df[\"Destination\"] == dest)).any():\n",
    "\t\t\tdf = df.append(\n",
    "\t\t\t\t{\"Departure\": dep, \"Destination\": dest, \"Price\": price},\n",
    "\t\t\t\tignore_index=True)\n",
    "\treturn df\n",
    "\n",
    "\n",
    "cities = [\"Beijing\", \"Moscow\", \"New-York\", \"Tokyo\", \"Paris\", \"Cairo\",\n",
    "\t\t  \"Santiago\", \"Lima\", \"Kinshasa\", \"Singapore\",\n",
    "\t\t  \"New-Delhi\", \"London\", \"Ankara\", \"Nairobi\", \"Ottawa\", \"Seoul\",\n",
    "\t\t  \"Tehran\", \"Guatemala\", \"Caracas\", \"Vienna\"]\n",
    "\n",
    "flights = create_flight_df(cities)\n",
    "flights.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItISmB4RYpcJ"
   },
   "source": [
    "As there are pairs of cities with no direct flight between them, let us find the pairs of cities that have a single connection flight between them and calculate the total price of the flgihts. To do so merge the two data frames. This operation is often referred to as \"joining\" with the options of inner, outer, left, right and cross joining. For more about merging `pandas` data frames read the [documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#database-style-dataframe-or-named-series-joining-merging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "RvJjgHEkQq6g"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  Departure_x Destination_x Price_x Departure_y Destination_y Price_y  \\\n0    New-York          Lima     343        Lima        London     113   \n1    New-York          Lima     343        Lima         Seoul     297   \n2    Santiago     Singapore     122   Singapore        Ankara     180   \n3        Lima         Seoul     297       Seoul        Tehran     193   \n4     Nairobi         Seoul     355       Seoul        Tehran     193   \n\n  Total_Price  \n0         456  \n1         640  \n2         302  \n3         490  \n4         548  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Departure_x</th>\n      <th>Destination_x</th>\n      <th>Price_x</th>\n      <th>Departure_y</th>\n      <th>Destination_y</th>\n      <th>Price_y</th>\n      <th>Total_Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>New-York</td>\n      <td>Lima</td>\n      <td>343</td>\n      <td>Lima</td>\n      <td>London</td>\n      <td>113</td>\n      <td>456</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>New-York</td>\n      <td>Lima</td>\n      <td>343</td>\n      <td>Lima</td>\n      <td>Seoul</td>\n      <td>297</td>\n      <td>640</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Santiago</td>\n      <td>Singapore</td>\n      <td>122</td>\n      <td>Singapore</td>\n      <td>Ankara</td>\n      <td>180</td>\n      <td>302</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Lima</td>\n      <td>Seoul</td>\n      <td>297</td>\n      <td>Seoul</td>\n      <td>Tehran</td>\n      <td>193</td>\n      <td>490</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Nairobi</td>\n      <td>Seoul</td>\n      <td>355</td>\n      <td>Seoul</td>\n      <td>Tehran</td>\n      <td>193</td>\n      <td>548</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(flights, flights, left_on=[\"Destination\"],\n",
    "\t\t\t  right_on=[\"Departure\"], how=\"inner\")\n",
    "df = df[df.Departure_x != df.Destination_y]\n",
    "df[\"Total_Price\"] = df[\"Price_x\"] + df[\"Price_y\"]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data frame with all flights of no connection and single connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "    Departure Destination Price\n0     Nairobi    Kinshasa   170\n1    New-York        Lima   343\n2    Santiago   Singapore   122\n3        Lima      London   113\n4        Lima       Seoul   297\n5      Ankara   New-Delhi   214\n6      Ottawa      London   257\n7      Tehran      Vienna   110\n8       Seoul      Tehran   193\n9       Tokyo      London   190\n10     Moscow    Kinshasa   146\n11      Paris     Caracas   378\n12  Singapore      Ankara   180\n13    Nairobi       Seoul   355\n14      Cairo   Guatemala   350\n15    Nairobi      Ankara   141\n16    Beijing      London   337\n17     Ottawa     Caracas   391\n18  Guatemala       Cairo   335\n19   New-York      London   295\n0    New-York      London   456\n1    New-York       Seoul   640\n2    Santiago      Ankara   302\n3        Lima      Tehran   490\n4     Nairobi      Tehran   548\n5       Seoul      Vienna   303\n6   Singapore   New-Delhi   394\n7     Nairobi   New-Delhi   355",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Departure</th>\n      <th>Destination</th>\n      <th>Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Nairobi</td>\n      <td>Kinshasa</td>\n      <td>170</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>New-York</td>\n      <td>Lima</td>\n      <td>343</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Santiago</td>\n      <td>Singapore</td>\n      <td>122</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Lima</td>\n      <td>London</td>\n      <td>113</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Lima</td>\n      <td>Seoul</td>\n      <td>297</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Ankara</td>\n      <td>New-Delhi</td>\n      <td>214</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Ottawa</td>\n      <td>London</td>\n      <td>257</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Tehran</td>\n      <td>Vienna</td>\n      <td>110</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Seoul</td>\n      <td>Tehran</td>\n      <td>193</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Tokyo</td>\n      <td>London</td>\n      <td>190</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Moscow</td>\n      <td>Kinshasa</td>\n      <td>146</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Paris</td>\n      <td>Caracas</td>\n      <td>378</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Singapore</td>\n      <td>Ankara</td>\n      <td>180</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Nairobi</td>\n      <td>Seoul</td>\n      <td>355</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Cairo</td>\n      <td>Guatemala</td>\n      <td>350</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Nairobi</td>\n      <td>Ankara</td>\n      <td>141</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Beijing</td>\n      <td>London</td>\n      <td>337</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Ottawa</td>\n      <td>Caracas</td>\n      <td>391</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Guatemala</td>\n      <td>Cairo</td>\n      <td>335</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>New-York</td>\n      <td>London</td>\n      <td>295</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>New-York</td>\n      <td>London</td>\n      <td>456</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>New-York</td>\n      <td>Seoul</td>\n      <td>640</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Santiago</td>\n      <td>Ankara</td>\n      <td>302</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Lima</td>\n      <td>Tehran</td>\n      <td>490</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Nairobi</td>\n      <td>Tehran</td>\n      <td>548</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Seoul</td>\n      <td>Vienna</td>\n      <td>303</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Singapore</td>\n      <td>New-Delhi</td>\n      <td>394</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Nairobi</td>\n      <td>New-Delhi</td>\n      <td>355</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights = flights.append(df[[\"Departure_x\", \"Destination_y\", \"Total_Price\"]]\n",
    "\t\t\t\t\t\t .rename(\n",
    "\tcolumns={\"Departure_x\": \"Departure\", \"Destination_y\": \"Destination\",\n",
    "\t\t\t \"Total_Price\": \"Price\"}))\n",
    "flights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "il0mLoEzhi6_"
   },
   "source": [
    "Since now we might have more than one way to flight between each pair of cities, let us find the cheapest flight option, with one connection, between two cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "nYli93a6bMjB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  Departure_x Destination_y  Total_Price\n0        Lima        Tehran          490\n1     Nairobi     New-Delhi          355\n2     Nairobi        Tehran          548\n3    New-York        London          456\n4    New-York         Seoul          640\n5    Santiago        Ankara          302\n6       Seoul        Vienna          303\n7   Singapore     New-Delhi          394",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Departure_x</th>\n      <th>Destination_y</th>\n      <th>Total_Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Lima</td>\n      <td>Tehran</td>\n      <td>490</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Nairobi</td>\n      <td>New-Delhi</td>\n      <td>355</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Nairobi</td>\n      <td>Tehran</td>\n      <td>548</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>New-York</td>\n      <td>London</td>\n      <td>456</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>New-York</td>\n      <td>Seoul</td>\n      <td>640</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Santiago</td>\n      <td>Ankara</td>\n      <td>302</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Seoul</td>\n      <td>Vienna</td>\n      <td>303</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Singapore</td>\n      <td>New-Delhi</td>\n      <td>394</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_by_group = df.groupby([\"Departure_x\", \"Destination_y\"], as_index=False)[\n",
    "\t\"Total_Price\"].min()\n",
    "min_by_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TI2CrtB5irgn"
   },
   "source": [
    "And if we want to know on average what is the most expensive city to fly to then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "DUdokeBWiq1V"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'Seoul'"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_by_dest = min_by_group.groupby(\"Destination_y\")[\"Total_Price\"].mean()\n",
    "expensive_city = mean_by_dest.idxmax()\n",
    "expensive_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lab-backround-numpy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}